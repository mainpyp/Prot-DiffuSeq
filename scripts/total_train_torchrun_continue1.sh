python -m torch.distributed.launch --nproc_per_node=8 --master_port=12233 --use_env run_train.py \
	--diff_steps 3000 \
	--lr 0.00001 \
	--learning_steps 1000001 \
	--save_interval 1000 \
	--seed 102 \
	--noise_schedule sqrt \
	--hidden_dim 1024 \
	--bsz 1024 \
	--dataset ProtTotal \
	--data_dir datasets/ProtTotal \
	--vocab protbert \
	--seq_len 256 \
	--schedule_sampler lossaware \
	--resume_checkpoint diffusion_models/diffuseq_ProtTotal_h1024_lr1e-05_t3000_sqrt_lossaware_seed102_ProtTotalFinalRun25620230531-23\:49\:24/ema_0.9999_014000.pt \
	--notes ProtTotalFinalRun256Continue
