python -m torch.distributed.launch --nproc_per_node=1 --master_port=12233 --use_env run_train.py \
--diff_steps 3000 \
--lr 0.00001 \
--learning_steps 50001 \
--save_interval 2500 \
--seed 102 \
--noise_schedule sqrt \
--hidden_dim 1024 \
--bsz 256 \
--dataset ProtTotal \
--data_dir datasets/ProtTotal \
--vocab protbert \
--seq_len 256 \
--schedule_sampler lossaware \
--notes ProtTotalLowLRZ
